# app.py (ê¶ê·¹ì˜ ë””ë²„ê¹… ë²„ì „)

import os
import streamlit as st
import time # ë””ë²„ê¹…ì„ ìœ„í•´ ì¶”ê°€

# ... (ë‹¤ë¥¸ import êµ¬ë¬¸ë“¤ì€ ì´ì „ê³¼ ë™ì¼)
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import concurrent.futures
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import numpy as np
import io
from services.dream_analyzer_service import DreamAnalyzerService
from services.report_generator_service import ReportGeneratorService
from services.image_generator_service import ImageGeneratorService
from services.stt_service import STTService

# --- ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ë° ì˜¤ë””ì˜¤ í•¸ë“¤ëŸ¬ (ì´ì „ê³¼ ë™ì¼) ---
st.set_page_config(page_title="ë³´ì—¬DREAM", page_icon="ğŸŒ™", layout="wide")
@st.cache_resource
def initialize_services():
    # ... (ì´ì „ê³¼ ë™ì¼)
    api_key = os.getenv("OPENAI_API_KEY");
    if not api_key: st.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); st.stop()
    try:
        embeddings = OpenAIEmbeddings(); vector_store = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True); retriever = vector_store.as_retriever()
        report_generator = ReportGeneratorService(api_key=api_key, retriever=retriever); dream_analyzer = DreamAnalyzerService(api_key=api_key); image_generator = ImageGeneratorService(api_key=api_key); stt_service = STTService(api_key=api_key)
        return report_generator, dream_analyzer, image_generator, stt_service
    except Exception as e:
        st.error(f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}"); st.info("faiss_index í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."); st.stop()
class AudioFrameHandler(AudioProcessorBase):
    def __init__(self): self.audio_frames = []
    def recv(self, frame): self.audio_frames.append(frame.to_ndarray()); return frame
    def get_audio_bytes(self):
        if not self.audio_frames: return None
        sound_chunk = np.concatenate(self.audio_frames); return io.BytesIO((sound_chunk * 32767).astype(np.int16).tobytes())

# --- ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ (ë””ë²„ê¹… print ì¶”ê°€) ---
def run_analysis_pipeline(dream_text):
    print("DEBUG: 1. run_analysis_pipeline í•¨ìˆ˜ ì‹œì‘ë¨.")
    if not dream_text or "ì˜¤ë¥˜" in dream_text or "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in dream_text:
        st.error(dream_text or "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."); print("DEBUG: ERROR! ë¶„ì„í•  í…ìŠ¤íŠ¸ ì—†ìŒ."); return
    st.session_state.analysis_results = None
    try:
        with st.spinner("RAGê°€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì°¸ì¡°í•˜ì—¬ ê¿ˆì„ ì‹¬ì¸µ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            print("DEBUG: 2. ë¦¬í¬íŠ¸ ìƒì„± ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œì‘...")
            dream_report = st.session_state.report_generator.generate_report_with_rag(dream_text)
            print("DEBUG: 3. ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ.")
            nightmare_prompt, reconstructed_prompt, summary, mappings = st.session_state.dream_analyzer.create_reconstructed_prompt_and_analysis(dream_text, dream_report)
            print("DEBUG: 4. í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ.")
        with st.spinner("DALL-E 3ê°€ ê¿ˆì„ ì´ë¯¸ì§€ë¡œ ê·¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤..."):
            print("DEBUG: 5. ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹œì‘...")
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future_nightmare = executor.submit(st.session_state.image_generator.generate_image_from_prompt, nightmare_prompt)
                future_reconstructed = executor.submit(st.session_state.image_generator.generate_image_from_prompt, reconstructed_prompt)
                nightmare_image_url = future_nightmare.result(); reconstructed_image_url = future_reconstructed.result()
            print("DEBUG: 6. ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ.")
        print("DEBUG: 7. ì„¸ì…˜ ìƒíƒœì— ëª¨ë“  ê²°ê³¼ ì €ì¥ ì‹œì‘...")
        st.session_state.analysis_results = { "dream_report": dream_report, "nightmare_image_url": nightmare_image_url, "reconstructed_image_url": reconstructed_image_url, "summary": summary, "mappings": mappings }
        print("DEBUG: 8. ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        print(f"DEBUG: ERROR! íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}"); st.error(f"ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def display_results():
    print("DEBUG: 10. display_results í•¨ìˆ˜ ì‹œì‘ë¨.")
    # ... (ì´ì „ê³¼ ë™ì¼)
    results = st.session_state.analysis_results; dream_report = results["dream_report"]
    st.subheader("ğŸ“ AI ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸")
    with st.container(border=True):
        st.markdown("##### ì‹¬ì¸µ ë¶„ì„ ìš”ì•½"); st.write(dream_report.get("analysis_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ"))
        st.markdown("##### ì£¼ìš” ê°ì •");
        for emo in dream_report.get("emotions", []): st.progress(emo['score'], text=f"{emo['emotion']} ({int(emo['score']*100)}%)")
        st.markdown("##### í•µì‹¬ í‚¤ì›Œë“œ"); st.write(" &nbsp; ".join(f"`{kw}`" for kw in dream_report.get("keywords", [])))
    st.divider()
    col1, col2 = st.columns(2);
    with col1:
        st.subheader("ì•…ëª½ì˜ ì‹œê°í™” (Before)");
        if results["nightmare_image_url"].startswith("http"): st.image(results["nightmare_image_url"], caption="AIê°€ ê·¸ë¦° ë‹¹ì‹ ì˜ ì•…ëª½")
        else: st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {results['nightmare_image_url']}")
    with col2:
        st.subheader("ì¬êµ¬ì„±ëœ ê¿ˆ (After)");
        if results["reconstructed_image_url"].startswith("http"): st.image(results["reconstructed_image_url"], caption="AIê°€ ê¸ì •ì ìœ¼ë¡œ ì¬êµ¬ì„±í•œ ê¿ˆ")
        else: st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {results['reconstructed_image_url']}")
    st.divider()
    st.subheader("âœ¨ ì´ë ‡ê²Œ ë°”ë€Œì—ˆì–´ìš”!"); st.write(results["summary"])
    for mapping in results["mappings"]: st.markdown(f"- `{mapping['original']}` &nbsp; â¡ï¸ &nbsp; **`{mapping['transformed']}`**")
    print("DEBUG: 11. display_results í•¨ìˆ˜ ì™„ë£Œ.")

# --- ë©”ì¸ ì•± ì‹¤í–‰ í•¨ìˆ˜ (ë””ë²„ê¹… print ë° st.rerun() ì¶”ê°€) ---
def main():
    print(f"\n--- SCRIPT RERUN AT {time.time()} ---")
    st.title("ë³´ì—¬DREAM ğŸŒ™")
    st.session_state.report_generator, st.session_state.dream_analyzer, st.session_state.image_generator, st.session_state.stt_service = initialize_services()
    if "transcribed_text" not in st.session_state: st.session_state.transcribed_text = ""
    if "analysis_results" not in st.session_state: st.session_state.analysis_results = None
    def handle_file_upload():
        if st.session_state.file_uploader:
            with st.spinner("..."):
                st.session_state.transcribed_text = st.session_state.stt_service.transcribe_from_bytes(st.session_state.file_uploader.getvalue())
                st.session_state.analysis_results = None
    tab1, tab2, tab3 = st.tabs(["âœï¸ í…ìŠ¤íŠ¸ë¡œ ì…ë ¥", "â¬†ï¸ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ¤ ì‹¤ì‹œê°„ ë…¹ìŒ"])
    with tab1:
        text_input = st.text_area("...", key="text_input_area")
        if st.button("ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸)", key="analyze_text"):
            print(">>> 'ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸)' ë²„íŠ¼ í´ë¦­ë¨"); run_analysis_pipeline(text_input); st.rerun()
    with tab2:
        st.file_uploader("...", key="file_uploader", on_change=handle_file_upload)
        if st.session_state.transcribed_text:
            st.text_area("...", value=st.session_state.transcribed_text, key="transcribed_text_area")
            if st.button("ë¶„ì„ ì‹œì‘ (ì—…ë¡œë“œ íŒŒì¼)", key="analyze_file"):
                print(">>> 'ë¶„ì„ ì‹œì‘ (ì—…ë¡œë“œ íŒŒì¼)' ë²„íŠ¼ í´ë¦­ë¨"); run_analysis_pipeline(st.session_state.transcribed_text); st.rerun()
    with tab3:
        webrtc_ctx = webrtc_streamer(...)
        if webrtc_ctx.audio_processor and st.button("ë…¹ìŒ ì™„ë£Œ ë° í…ìŠ¤íŠ¸ ë³€í™˜", key="transcribe_mic"):
            # ... (ì´ì „ê³¼ ë™ì¼)
            audio_bytes_io = webrtc_ctx.audio_processor.get_audio_bytes()
            if audio_bytes_io:
                with st.spinner("..."):
                    st.session_state.transcribed_text = st.session_state.stt_service.transcribe_from_bytes(audio_bytes_io.getvalue())
                    st.session_state.analysis_results = None
            else: st.warning("ë…¹ìŒëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        if st.session_state.transcribed_text:
            st.text_area("...", value=st.session_state.transcribed_text, key="mic_text_area")
            if st.button("ë¶„ì„ ì‹œì‘ (ë…¹ìŒ ë‚´ìš©)", key="analyze_mic"):
                print(">>> 'ë¶„ì„ ì‹œì‘ (ë…¹ìŒ ë‚´ìš©)' ë²„íŠ¼ í´ë¦­ë¨"); run_analysis_pipeline(st.session_state.transcribed_text); st.rerun()

    print(f"--- Final Check (analysis_results is None: {st.session_state.analysis_results is None}) ---")
    if st.session_state.analysis_results:
        display_results()
    print("--- SCRIPT END ---")

if __name__ == "__main__":
    main()