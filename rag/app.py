import os
import streamlit as st
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import concurrent.futures
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import numpy as np
import io

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“  ì„œë¹„ìŠ¤ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from services.dream_analyzer_service import DreamAnalyzerService
from services.report_generator_service import ReportGeneratorService
from services.image_generator_service import ImageGeneratorService
from services.stt_service import STTService

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ---
st.set_page_config(page_title="ë³´ì—¬DREAM", page_icon="ğŸŒ™", layout="wide")

@st.cache_resource
def initialize_services():
    """ API í‚¤ í™•ì¸, ëª¨ë“  ì„œë¹„ìŠ¤ ë° ëª¨ë¸ ê°ì²´ë“¤ì„ ìƒì„±í•˜ê³  ìºì‹±í•©ë‹ˆë‹¤. """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key: st.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); st.stop()
    try:
        embeddings = OpenAIEmbeddings()
        vector_store = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
        retriever = vector_store.as_retriever()
        report_generator = ReportGeneratorService(api_key=api_key, retriever=retriever)
        dream_analyzer = DreamAnalyzerService(api_key=api_key)
        image_generator = ImageGeneratorService(api_key=api_key)
        stt_service = STTService(api_key=api_key)
        return report_generator, dream_analyzer, image_generator, stt_service
    except Exception as e:
        st.error(f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}"); st.info("faiss_index í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."); st.stop()

# --- 2. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë…¹ìŒ ì²˜ë¦¬ í´ë˜ìŠ¤ ---
class AudioFrameHandler(AudioProcessorBase):
    def __init__(self): self.audio_frames = []
    def recv(self, frame): self.audio_frames.append(frame.to_ndarray()); return frame
    def get_audio_bytes(self):
        if not self.audio_frames: return None
        sound_chunk = np.concatenate(self.audio_frames)
        return io.BytesIO((sound_chunk * 32767).astype(np.int16).tobytes())

# --- 3. ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•œ ê³µí†µ í•¨ìˆ˜ ---
def run_analysis_pipeline(dream_text):
    """ ì…ë ¥ë°›ì€ í…ìŠ¤íŠ¸ë¡œ ì „ì²´ ë¶„ì„/ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ê³ , ê²°ê³¼ë¥¼ st.session_stateì— ì €ì¥í•©ë‹ˆë‹¤. """
    if not dream_text or "ì˜¤ë¥˜" in dream_text or "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in dream_text:
        st.error(dream_text or "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    st.session_state.analysis_results = None
    with st.spinner("RAGê°€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì°¸ì¡°í•˜ì—¬ ê¿ˆì„ ì‹¬ì¸µ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        dream_report = st.session_state.report_generator.generate_report_with_rag(dream_text)
        nightmare_prompt, reconstructed_prompt, summary, mappings = st.session_state.dream_analyzer.create_reconstructed_prompt_and_analysis(dream_text, dream_report)
    with st.spinner("DALL-E 3ê°€ ê¿ˆì„ ì´ë¯¸ì§€ë¡œ ê·¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤... (1ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_nightmare = executor.submit(st.session_state.image_generator.generate_image_from_prompt, nightmare_prompt)
            future_reconstructed = executor.submit(st.session_state.image_generator.generate_image_from_prompt, reconstructed_prompt)
            nightmare_image_url = future_nightmare.result()
            reconstructed_image_url = future_reconstructed.result()
    st.session_state.analysis_results = {
        "dream_report": dream_report,
        "nightmare_image_url": nightmare_image_url,
        "reconstructed_image_url": reconstructed_image_url,
        "summary": summary,
        "mappings": mappings
    }

def display_results():
    """ st.session_stateì— ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤. """
    results = st.session_state.analysis_results
    dream_report = results["dream_report"]
    st.subheader("ğŸ“ AI ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸")
    with st.container(border=True):
        st.markdown("##### ì‹¬ì¸µ ë¶„ì„ ìš”ì•½"); st.write(dream_report.get("analysis_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ"))
        st.markdown("##### ì£¼ìš” ê°ì •")
        for emo in dream_report.get("emotions", []): st.progress(emo['score'], text=f"{emo['emotion']} ({int(emo['score']*100)}%)")
        st.markdown("##### í•µì‹¬ í‚¤ì›Œë“œ"); st.write(" &nbsp; ".join(f"`{kw}`" for kw in dream_report.get("keywords", [])))
    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ì•…ëª½ì˜ ì‹œê°í™” (Before)");
        if results["nightmare_image_url"].startswith("http"): st.image(results["nightmare_image_url"], caption="AIê°€ ê·¸ë¦° ë‹¹ì‹ ì˜ ì•…ëª½")
        else: st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {results['nightmare_image_url']}")
    with col2:
        st.subheader("ì¬êµ¬ì„±ëœ ê¿ˆ (After)");
        if results["reconstructed_image_url"].startswith("http"): st.image(results["reconstructed_image_url"], caption="AIê°€ ê¸ì •ì ìœ¼ë¡œ ì¬êµ¬ì„±í•œ ê¿ˆ")
        else: st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {results['reconstructed_image_url']}")
    st.divider()
    st.subheader("âœ¨ ì´ë ‡ê²Œ ë°”ë€Œì—ˆì–´ìš”!"); st.write(results["summary"])
    for mapping in results["mappings"]: st.markdown(f"- `{mapping['original']}` &nbsp; â¡ï¸ &nbsp; **`{mapping['transformed']}`**")

# --- 4. ë©”ì¸ ì•± ì‹¤í–‰ ---
def main():
    st.title("ë³´ì—¬DREAM ğŸŒ™")
    st.write("ë‹¹ì‹ ì˜ ê¿ˆ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”. AIê°€ ì•…ëª½ì„ ë¶„ì„í•˜ê³  ê¸ì •ì ì¸ ì´ë¯¸ì§€ë¡œ ì¬êµ¬ì„±í•´ ë“œë¦½ë‹ˆë‹¤.")
    
    st.session_state.report_generator, st.session_state.dream_analyzer, st.session_state.image_generator, st.session_state.stt_service = initialize_services()

    if "transcribed_text" not in st.session_state: st.session_state.transcribed_text = ""
    if "analysis_results" not in st.session_state: st.session_state.analysis_results = None

    tab1, tab2, tab3 = st.tabs(["âœï¸ í…ìŠ¤íŠ¸ë¡œ ì…ë ¥", "â¬†ï¸ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ¤ ì‹¤ì‹œê°„ ë…¹ìŒ"])
    with tab1:
        dream_text_input = st.text_area("ì–´ì ¯ë°¤ ì–´ë–¤ ê¿ˆì„ ê¾¸ì…¨ë‚˜ìš”?", height=200, key="text_input")
        if st.button("ë¶„ì„ ì‹œì‘ (í…ìŠ¤íŠ¸)", type="primary", use_container_width=True, key="analyze_text"):
            run_analysis_pipeline(dream_text_input)
    with tab2:
        uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼(mp3, wav, m4a ë“±)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['mp3', 'm4a', 'wav', 'ogg'], key="file_uploader")
        if uploaded_file and st.button("ì´ íŒŒì¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜í•˜ê¸°", use_container_width=True, key="transcribe_file"):
            with st.spinner("ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state.transcribed_text = st.session_state.stt_service.transcribe_from_bytes(uploaded_file.getvalue())
        st.text_area("**ë³€í™˜ëœ í…ìŠ¤íŠ¸**", value=st.session_state.transcribed_text, height=150, key="transcribed_text_file")
        if st.session_state.transcribed_text and st.button("ë¶„ì„ ì‹œì‘ (ì—…ë¡œë“œ íŒŒì¼)", type="primary", use_container_width=True, key="analyze_file"):
            run_analysis_pipeline(st.session_state.transcribed_text)
    with tab3:
        st.write("ì•„ë˜ 'START' ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§ˆì´í¬ì— ê¿ˆ ì´ì•¼ê¸°ë¥¼ ë…¹ìŒí•˜ì„¸ìš”.")
        webrtc_ctx = webrtc_streamer(key="audio-recorder", mode=WebRtcMode.SENDONLY, audio_processor_factory=AudioFrameHandler)
        if webrtc_ctx.audio_processor and st.button("ë…¹ìŒ ë‚´ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜", use_container_width=True, key="transcribe_mic"):
            audio_bytes_io = webrtc_ctx.audio_processor.get_audio_bytes()
            if audio_bytes_io:
                with st.spinner("ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤..."):
                    st.session_state.transcribed_text = st.session_state.stt_service.transcribe_from_bytes(audio_bytes_io.getvalue())
            else: st.warning("ë…¹ìŒëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.text_area("**ë³€í™˜ëœ í…ìŠ¤íŠ¸**", value=st.session_state.transcribed_text, height=150, key="transcribed_text_mic")
        if st.session_state.transcribed_text and st.button("ë¶„ì„ ì‹œì‘ (ë…¹ìŒ ë‚´ìš©)", type="primary", use_container_width=True, key="analyze_mic"):
            run_analysis_pipeline(st.session_state.transcribed_text)

    if st.session_state.analysis_results:
        display_results()

if __name__ == "__main__":
    main()