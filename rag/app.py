import os
import streamlit as st
import time
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import concurrent.futures
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
import numpy as np
import io

# ìš°ë¦¬ê°€ ë§Œë“  ëª¨ë“  ì„œë¹„ìŠ¤ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from services.dream_analyzer_service import DreamAnalyzerService
from services.report_generator_service import ReportGeneratorService
from services.image_generator_service import ImageGeneratorService
from services.stt_service import STTService

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ---
st.set_page_config(page_title="ë³´ì—¬DREAM", page_icon="ğŸŒ™", layout="wide")

@st.cache_resource
def initialize_services():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key: st.error("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); st.stop()
    try:
        embeddings = OpenAIEmbeddings(); vector_store = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True); retriever = vector_store.as_retriever()
        report_generator = ReportGeneratorService(api_key=api_key, retriever=retriever); dream_analyzer = DreamAnalyzerService(api_key=api_key); image_generator = ImageGeneratorService(api_key=api_key); stt_service = STTService(api_key=api_key)
        return report_generator, dream_analyzer, image_generator, stt_service
    except Exception as e:
        st.error(f"ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}"); st.info("faiss_index í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."); st.stop()

# --- 2. ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë…¹ìŒ ì²˜ë¦¬ í´ë˜ìŠ¤ ---
class AudioFrameHandler(AudioProcessorBase):
    def __init__(self): self.audio_frames = []
    def recv(self, frame): self.audio_frames.append(frame.to_ndarray()); return frame
    def get_audio_bytes(self):
        if not self.audio_frames: return None
        sound_chunk = np.concatenate(self.audio_frames); return io.BytesIO((sound_chunk * 32767).astype(np.int16).tobytes())

# --- 3. ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œë¥¼ ìœ„í•œ ê³µí†µ í•¨ìˆ˜ ---
def run_analysis_pipeline(dream_text):
    if not dream_text or "ì˜¤ë¥˜" in dream_text or "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in dream_text:
        st.error(dream_text or "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."); return
    st.session_state.analysis_results = None; st.session_state.show_before_image = False; st.session_state.show_after_image = False
    with st.spinner("RAGê°€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì°¸ì¡°í•˜ì—¬ ê¿ˆì„ ì‹¬ì¸µ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        dream_report = st.session_state.report_generator.generate_report_with_rag(dream_text)
        nightmare_prompt, reconstructed_prompt, summary, mappings = st.session_state.dream_analyzer.create_reconstructed_prompt_and_analysis(dream_text, dream_report)
    with st.spinner("DALL-E 3ê°€ ê¿ˆì„ ì´ë¯¸ì§€ë¡œ ê·¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤..."):
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_nightmare = executor.submit(st.session_state.image_generator.generate_image_from_prompt, nightmare_prompt)
            future_reconstructed = executor.submit(st.session_state.image_generator.generate_image_from_prompt, reconstructed_prompt)
            nightmare_image_url = future_nightmare.result(); reconstructed_image_url = future_reconstructed.result()
    st.session_state.analysis_results = { "dream_report": dream_report, "nightmare_image_url": nightmare_image_url, "reconstructed_image_url": reconstructed_image_url, "summary": summary, "mappings": mappings }

def display_results():
    results = st.session_state.analysis_results; dream_report = results["dream_report"]
    st.subheader("ğŸ“ AI ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸")
    with st.container(border=True):
        st.markdown("##### ì‹¬ì¸µ ë¶„ì„ ìš”ì•½"); st.write(dream_report.get("analysis_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ"))
        st.markdown("##### ì£¼ìš” ê°ì •");
        for emo in dream_report.get("emotions", []): st.progress(emo.get('score', 0), text=f"{emo.get('emotion', 'ì•Œ ìˆ˜ ì—†ìŒ')} ({int(emo.get('score', 0)*100)}%)")
        st.markdown("##### í•µì‹¬ í‚¤ì›Œë“œ"); st.write(" &nbsp; ".join(f"`{kw}`" for kw in dream_report.get("keywords", [])))
    st.divider()
    col1, col2 = st.columns(2);
    with col1:
        st.subheader("ì•…ëª½ì˜ ì‹œê°í™” (Before)");
        if st.button("ì•…ëª½ ì´ë¯¸ì§€ ë³´ê¸°", key="show_before"): st.session_state.show_before_image = not st.session_state.show_before_image
        if st.session_state.show_before_image:
            if results["nightmare_image_url"].startswith("http"): st.image(results["nightmare_image_url"], caption="AIê°€ ê·¸ë¦° ë‹¹ì‹ ì˜ ì•…ëª½")
            else: st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {results['nightmare_image_url']}")
    with col2:
        st.subheader("ì¬êµ¬ì„±ëœ ê¿ˆ (After)");
        if st.button("ì¬êµ¬ì„±ëœ ê¿ˆ ì´ë¯¸ì§€ ë³´ê¸°", key="show_after"): st.session_state.show_after_image = not st.session_state.show_after_image
        if st.session_state.show_after_image:
            if results["reconstructed_image_url"].startswith("http"): st.image(results["reconstructed_image_url"], caption="AIê°€ ê¸ì •ì ìœ¼ë¡œ ì¬êµ¬ì„±í•œ ê¿ˆ")
            else: st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {results['reconstructed_image_url']}")
    st.divider()
    st.subheader("âœ¨ ì´ë ‡ê²Œ ë°”ë€Œì—ˆì–´ìš”!"); st.write(results["summary"])
    for mapping in results["mappings"]: st.markdown(f"- `{mapping['original']}` &nbsp; â¡ï¸ &nbsp; **`{mapping['transformed']}`**")

# --- 4. ë©”ì¸ ì•± ì‹¤í–‰ ---
def main():
    st.title("ë³´ì—¬DREAM ğŸŒ™"); st.write("ë‹¹ì‹ ì˜ ê¿ˆ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”. AIê°€ ì•…ëª½ì„ ë¶„ì„í•˜ê³  ê¸ì •ì ì¸ ì´ë¯¸ì§€ë¡œ ì¬êµ¬ì„±í•´ ë“œë¦½ë‹ˆë‹¤.")
    st.session_state.report_generator, st.session_state.dream_analyzer, st.session_state.image_generator, st.session_state.stt_service = initialize_services()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "dream_text" not in st.session_state: st.session_state.dream_text = ""
    if "analysis_results" not in st.session_state: st.session_state.analysis_results = None
    if "show_before_image" not in st.session_state: st.session_state.show_before_image = False
    if "show_after_image" not in st.session_state: st.session_state.show_after_image = False

    # --- ì…ë ¥ UI í†µí•© ---
    st.subheader("1. ê¿ˆ ë‚´ìš© ì…ë ¥í•˜ê¸°")
    st.write("í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì‹œê±°ë‚˜, ì•„ë˜ ìŒì„± ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì±„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # ì¤‘ì•™ í…ìŠ¤íŠ¸ ì…ë ¥ ì˜ì—­ (ëª¨ë“  ì…ë ¥ì˜ ê²°ê³¼ê°€ ì—¬ê¸°ë¡œ ëª¨ì„)
    st.session_state.dream_text = st.text_area(
        "ê¿ˆ ë‚´ìš© ì…ë ¥ ë° í™•ì¸",
        value=st.session_state.dream_text,
        height=200,
        key="main_text_area"
    )

    # ìŒì„± ì…ë ¥ ì„¹ì…˜
    with st.expander("ìŒì„±ìœ¼ë¡œ ì…ë ¥í•˜ê¸° (íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” ì‹¤ì‹œê°„ ë…¹ìŒ)"):
        col_upload, col_record = st.columns(2)
        with col_upload:
            uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ ì—…ë¡œë“œ", type=['mp3', 'm4a', 'wav', 'ogg'], label_visibility="collapsed")
            if uploaded_file:
                with st.spinner("íŒŒì¼ ë³€í™˜ ì¤‘..."):
                    audio_bytes = uploaded_file.getvalue()
                    st.session_state.dream_text = st.session_state.stt_service.transcribe_from_bytes(audio_bytes)
                    st.session_state.analysis_results = None
                    st.rerun() # í…ìŠ¤íŠ¸ ìƒì ì¦‰ì‹œ ì—…ë°ì´íŠ¸

        with col_record:
            webrtc_ctx = webrtc_streamer(key="audio-recorder", mode=WebRtcMode.SENDONLY, audio_processor_factory=AudioFrameHandler)
            if webrtc_ctx.audio_processor and st.button("ë…¹ìŒ ë‚´ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜", use_container_width=True):
                audio_bytes_io = webrtc_ctx.audio_processor.get_audio_bytes()
                if audio_bytes_io:
                    with st.spinner("ë…¹ìŒ ë³€í™˜ ì¤‘..."):
                        st.session_state.dream_text = st.session_state.stt_service.transcribe_from_bytes(audio_bytes_io.getvalue())
                        st.session_state.analysis_results = None
                        st.rerun() # í…ìŠ¤íŠ¸ ìƒì ì¦‰ì‹œ ì—…ë°ì´íŠ¸
                else: st.warning("ë…¹ìŒëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ì¤‘ì•™ ë¶„ì„ ë²„íŠ¼ (ë‹¨ í•˜ë‚˜ë§Œ ì¡´ì¬)
    st.divider()
    if st.button("ë¶„ì„ ë° ì¬êµ¬ì„± ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
        # ì¤‘ì•™ í…ìŠ¤íŠ¸ ìƒìì˜ ê°’ì„ ê°€ì ¸ì™€ ë¶„ì„ ì‹¤í–‰
        text_to_analyze = st.session_state.main_text_area
        run_analysis_pipeline(text_to_analyze)
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if st.session_state.analysis_results:
        display_results()

if __name__ == "__main__":
    main()